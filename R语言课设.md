# R语言分类预测与主成分分析课程设计报告

## 第一章 课程设计概述

### 1.1 设计目的与任务

本次课程设计旨在通过R语言深入实践数据挖掘与统计分析的核心算法，具体涵盖分类预测与降维分析两大领域，目的是培养利用统计学方法解决实际商业与经济问题的能力。设计任务主要分为两个独立但互为补充的案例进行。

第一个案例聚焦于商业智能领域的精准营销问题。任务要求基于已有的用户注册信息（包含年龄、收入等级、是否学生、信用等级等特征）与历史购买记录，构建监督学习模型，以预测新注册用户购买计算机的可能性。在此过程中，需要分别应用`rpart`扩展包中的决策树算法与`klaR`包中的朴素贝叶斯（Naive Bayes）算法建立分类模型。这不仅要求掌握模型的构建过程，还需要对特定测试样本（X）进行分类判定，并输出相应的预测概率，从而评估模型的准确性，为广告推荐策略提供可靠的数据支持。

第二个案例则转向多元统计分析，针对15个行业的8项关键经济指标数据进行主成分分析（PCA）。面对多维度的复杂经济数据，任务要求首先计算样本数据的相关系数矩阵以检验变量间的相关性，随后利用主成分分析方法提取主要因子。设计要求依据累积贡献率不低于85%的标准确定主成分个数，并写出主成分表达式，结合实际经济背景解释各主成分的统计含义。此外，还需计算各样本在主成分上的得分，并通过绘制碎石图、载荷散点图以及双坐标图（Biplot）等可视化手段，直观地展示变量间的结构关系及样本在低维空间中的分布特征。

### 1.2 实验环境与工具

本实验在通用的计算机操作环境下进行，核心分析工具为R语言及其配套的集成开发环境RStudio。R语言作为一种强大的开源统计计算与绘图语言，拥有庞大且活跃的社区支持，能够高效完成从数据清洗、统计建模到结果可视化的全过程。

在具体的代码实现与算法应用上，针对不同的案例任务加载了相应的扩展包。对于分类预测任务，主要依赖`rpart`包来构建分类回归树模型，并配合`rpart.plot`包实现决策树的图形化展示，以便于直观理解分类规则；同时，引入`klaR`包调用其中的`NaiveBayes`函数，以实现基于概率论的贝叶斯分类。对于主成分分析任务，使用了`readxl`包来处理外部Excel格式的企业经济数据，核心分析则调用R语言内置的`princomp`函数执行，辅以R基础绘图系统（Base Plot）完成碎石图、散点图及双坐标图的绘制。这些工具与环境的组合，确保了实验数据的准确读取、模型的规范构建以及分析结果的有效呈现。


## 第二章 案例一：计算机购买行为的分类预测

### 2.1 数据准备与预处理

本案例的分析基础来源于一份包含16条记录的用户调查数据。在R语言环境中，首先构建了包含年龄（Age）、收入等级（Income_level）、是否学生（Student）、信用等级（Credit_rate）以及目标变量是否购买计算机（Class）的数据框（DataFrame）。为了适应后续分类算法的要求，所有字符型变量均被显式转换为因子（Factor）类型，确保模型能够正确识别类别属性而非文本字符串。

为了实现对特定用户的推荐预测，我们定义了一个待预测的新样本X。根据题目设定，该用户的特征描述为：年龄在30岁以下、收入水平中等、身份为学生且信用状况良好。在构建该样本数据时，特别注意保持了各特征因子的水平（Levels）与训练数据集完全一致，这是确保模型能够顺利接受输入并进行有效预测的前提条件。

### 2.2 rpart决策树模型分析

利用`rpart`扩展包，我们建立了分类回归树模型，旨在通过一系列的逻辑规则将用户群体划分为购买者与非购买者。在模型构建过程中，考虑到训练样本量较少（仅16例），我们将控制参数`minsplit`设定为2，允许对极小的节点进行分裂，同时将复杂度参数`cp`设定为0.001，以确保决策树能够充分生长，捕捉数据中的细微模式。

通过`print`函数输出的模型结构及`rpart.plot`生成的决策树可视化图（图 14-1）可以清晰地观察到分类规则的生成过程。根节点首先根据“年龄”属性进行分裂，将31至40岁的用户直接划分为购买人群（概率100%）。对于30岁以下及40岁以上的用户，模型进一步考察“收入等级”；若收入为“高”，则判定为不购买。对于收入为“中”或“低”的用户，决策路径继续向下延伸，依次依据“信用等级”和“年龄”进行细分。

针对待预测样本X（30岁以下，收入中等，学生，信用良好），我们沿着决策树的路径进行推演：首先，因年龄属于“30岁以下”，进入左侧分支；其次，因收入为“中”，避开了“高收入不购买”的节点，进入下一层级；随后，在信用等级为“良”的分支下，结合年龄再次判定，最终落入叶节点（Node 44）。模型输出结果显示，样本X被分类为“否”（不购买）。根据预测概率矩阵，该样本不购买的概率约为66.7%，而购买的概率仅为33.3%。这表明在决策树模型的逻辑下，虽然该用户具备某些潜在购买特征，但综合年龄与收入组合来看，其购买意愿倾向于消极。

### 2.3 NaiveBayes朴素贝叶斯模型分析

为了验证分类结果的稳健性，我们引入了基于概率统计的朴素贝叶斯模型。利用`klaR`包中的`NaiveBayes`函数，模型计算了类别的先验概率及各特征在给定类别下的条件概率。模型输出显示，整体人群购买计算机的先验概率为0.625，高于不购买的0.375。通过绘制条件分布图（图 14-2），我们可以直观地看到各变量在不同类别下的分布差异，例如在“是否学生”这一特征上，购买者中是学生的比例显著高于非购买者。

将样本X输入贝叶斯模型进行预测，得到了与决策树截然不同的结果。预测输出显示样本X的分类结果为“是”（购买）。进一步查看后验概率（Posterior Probabilities），该用户购买计算机的概率高达65.4%，而不购买的概率仅为34.6%。出现这种反转的原因在于朴素贝叶斯算法假设各特征相互独立，它捕捉到了样本X身上“学生”和“信用良好”这两个特征与“购买”行为之间存在的强正相关性（如模型显示，购买者中学生占比高，且信用良好的条件概率也较高）。尽管“30岁以下”通常倾向于不购买，但“学生”和“信用良好”的联合概率优势在此模型中占据了主导地位，从而导致最终判定该用户为潜在购买者。这一对比结果提示我们在实际业务推荐中，单一模型可能存在偏差，综合考虑多种算法结果能提供更全面的决策依据。
## 第二章 案例一：计算机购买行为的分类预测

### 2.1 数据准备与预处理

在进行分类预测模型构建之前，首要任务是将原始数据转化为R语言能够识别和处理的格式。本案例中的数据集包含16个训练样本，涵盖了用户的年龄（Age）、收入等级（Income_level）、是否学生（Student）和信用等级（Credit_rate）四个特征属性，以及一个目标属性——是否购买计算机（Class）。

在数据预处理阶段，利用`data.frame`函数构建数据框。由于所有的特征变量和目标变量均为类别型数据（Categorical Data），而非连续数值，因此在构建数据时，严格使用`factor`函数将所有字符向量转换为因子类型。因子的水平（Levels）被明确指定，例如年龄分为“30以下”、“31到40”和“40以上”，以确保模型能够正确理解变量的类别属性。与此同时，针对题目要求的待预测新样本$X$（30岁以下，收入中等，学生，信用良好），我们同样将其构建为一个包含相同因子水平的单行数据框`new_sample`，确保其结构与训练集完全一致，为后续的“回代”预测做好准备。

### 2.2 rpart决策树模型分析

#### 2.2.1 决策树模型的构建原理与实现

决策树是一种类似于流程图的树结构，其核心思想通过对数据特征的递归划分来构建分类规则。在本案例中，我们使用了`rpart`包来构建分类回归树（CART）。CART算法在分类任务中，通常采用基尼指数（Gini Index）作为特征选择的分裂标准。假设数据集$D$包含$K$个类别，样本点属于第$k$类的概率为$p_k$，则数据集的基尼值定义为：

$$ Gini(D) = 1 - \sum_{k=1}^{K} p_k^2 $$

算法会遍历所有特征的可能划分点，选择使得划分后基尼指数最小（即纯度提升最大）的特征进行分裂。在代码实现中，通过`rpart()`函数，设定`method = "class"`明确指定进行分类树的构建。为了防止过拟合或欠拟合，通过`rpart.control`参数将最小分裂样本数`minsplit`设为2，并将复杂度参数`cp`设为0.001，这使得树模型能够生长得足够精细，以捕捉样本中的细微模式。

<<<---图14-1（决策树分类结果可视化图，展示树的节点分裂与叶节点分布）--->>>

#### 2.2.2 决策树可视化与样本X预测

通过`rpart.plot`函数生成的可视化决策树（如上图14-1所示），我们可以清晰地追踪样本的分类路径。对于待预测样本$X$（Age=30以下，Income=中，Student=是，Credit=良），在决策树中经历的判别路径如下：
1.  **根节点**：首先根据**Age**进行判断，样本属于“30以下”，进入左分支。
2.  **二级节点**：接着判断**Income_level**，样本为“中”，属于“低/中”组合，进入右分支。
3.  **三级节点**：随后判断**Credit_rate**，样本为“良”，进入左分支。
4.  **四级节点**：再次根据**Age**细分，样本为“30以下”，进入左分支。
5.  **叶节点**：最后根据**Income_level**为“中”，落入最终的叶节点。

该叶节点的统计结果显示，属于该路径的训练样本倾向于“不购买”。根据模型输出的预测结果，样本$X$被分类为**“否”**（即不会购买计算机）。具体概率分布显示，该用户不购买的概率约为**66.7%**，而购买的概率仅为33.3%。这表明在决策树模型的逻辑下，尽管该用户是学生，但结合其年龄、中等收入和良好的信用状况，其购买倾向并不显著。

### 2.3 NaiveBayes朴素贝叶斯模型分析

#### 2.3.1 贝叶斯模型原理与构建

朴素贝叶斯分类器是基于贝叶斯定理与特征条件独立假设的概率模型。其数学基础在于计算样本$X$属于类别$C_i$的后验概率$P(C_i|X)$。根据贝叶斯公式：

$$ P(C_i|X) = \frac{P(X|C_i)P(C_i)}{P(X)} $$

由于分母$P(X)$对于所有类别是常数，分类决策主要取决于分子。朴素贝叶斯假设各特征之间相互独立，因此可以将联合概率$P(X|C_i)$分解为各特征条件概率的乘积：

$$ P(X|C_i) = \prod_{j=1}^{n} P(x_j|C_i) $$

在R语言中，利用`klaR`包的`NaiveBayes()`函数构建模型。该函数自动计算了先验概率$P(C_i)$以及在每个类别下各特征的条件概率分布。通过绘制模型图，可以直观地观察到不同特征在“是”与“否”两个类别下的概率密度差异。

<<<---图14-2（朴素贝叶斯模型特征条件概率分布图）--->>>

#### 2.3.2 样本X的后验概率计算与分类结果

利用建立的朴素贝叶斯模型对样本$X$进行预测，结果呈现出与决策树截然不同的结论。模型输出显示，样本$X$被分类为**“是”**（即会购买计算机）。

具体的后验概率计算结果如下：
*   **不购买（否）的后验概率**：0.346
*   **购买（是）的后验概率**：0.654

这意味着，从概率统计的角度来看，考虑到所有特征的综合影响（特别是“学生”这一特征在贝叶斯模型中可能贡献了较高的购买条件概率），该用户购买计算机的可能性高达**65.4%**。这一结果与决策树结果的差异（决策树预测为“否”），体现了不同算法在处理小样本数据时对特征权重的理解差异：决策树通过硬性的规则切割空间，而朴素贝叶斯则综合了所有特征的概率贡献。在本案例中，贝叶斯模型给出的购买概率更高，可能更敏锐地捕捉到了“学生”群体购买计算机的高倾向性。
## 第三章 案例二：行业经济指标的主成分分析

### 3.1 数据相关性检验

#### 3.1.1 数据读取与相关性原理
主成分分析（Principal Component Analysis, PCA）的核心目标是针对存在多重共线性的高维变量进行降维。在本案例中，我们处理的数据集包含15个企业的8项经济指标（如固定资产净值$X_1$、职工人数$X_2$、工业总产值$X_3$等）。在分析之初，利用`read_excel`读取数据并进行标准化预处理是必要的步骤。

为了验证进行主成分分析的必要性，我们需要考察变量间的相关性。对于任意两个变量$X_i$和$X_j$，其样本相关系数$r_{ij}$计算公式为：

$$ r_{ij} = \frac{\sum_{k=1}^{n} (x_{ki} - \bar{x}_i)(x_{kj} - \bar{x}_j)}{\sqrt{\sum_{k=1}^{n} (x_{ki} - \bar{x}_i)^2} \sqrt{\sum_{k=1}^{n} (x_{kj} - \bar{x}_j)^2}} $$

通过R语言计算得到的样本相关系数矩阵显示，部分变量间存在极强的线性相关性。例如，“固定资产净值”与“工业总产值”的相关系数高达0.938，“职工人数”与“固定资产净值”的相关系数为0.912。这种高度的相关性表明原始变量间存在显著的信息重叠，若直接进行分析容易导致模型的不稳定，这正是引入主成分分析进行降维的充分理由。

### 3.2 主成分提取与模型建立

#### 3.2.1 主成分提取原理与碎石图分析
主成分分析通过正交变换将一组可能相关的变量转换为一组线性不相关的变量（即主成分）。从数学角度看，这是求解相关系数矩阵的特征值$\lambda$和特征向量$u$的过程。第$i$个主成分$Y_i$是原始变量标准化后的线性组合，且满足方差最大化原则：

$$ Y_i = u_{i1}X_1 + u_{i2}X_2 + \dots + u_{i8}X_8 $$

为了直观判定需要保留的主成分个数，我们绘制了碎石图（Scree Plot）。碎石图的纵轴代表特征值（即主成分的方差），图形中坡度变平缓的点通常作为截断点。

<<<---图15-1（碎石图，展示各主成分的方差大小及下降趋势）--->>>

如图15-1所示，前三个主成分的特征值较高，且曲线在第三个主成分后趋于平缓，这初步暗示了提取前三个主成分可能是一个合理的选择。

#### 3.2.2 基于累积贡献率的主成分确定
根据题目要求，我们采用累积方差贡献率（Cumulative Proportion of Variance）作为确定主成分个数的定量标准。累积贡献率$G_m$定义为前$m$个主成分的特征值之和占总特征值之和的比例：

$$ G_m = \frac{\sum_{i=1}^{m} \lambda_i}{\sum_{j=1}^{p} \lambda_j} $$

`summary(fit_pca)`的输出结果显示：
*   第一主成分（Comp.1）贡献率：39.17%
*   第二主成分（Comp.2）贡献率：34.58%
*   第三主成分（Comp.3）贡献率：14.34%

前三个主成分的累积贡献率为 $0.3917 + 0.3458 + 0.1434 = 0.8809$（即88.1%）。由于该值超过了题目设定的85%的阈值，因此最终确定保留**3个**主成分。

### 3.3 结果解释与应用

#### 3.3.1 主成分载荷矩阵与实际含义
通过分析载荷矩阵（Loadings Matrix），我们可以推导出主成分的表达式并赋予其经济学含义。载荷反映了原始变量与主成分之间的相关程度。

1.  **第一主成分 ($Y_1$)**：
    $$ Y_1 \approx 0.42X_1 + 0.40X_2 - 0.44X_5 - 0.43X_6 $$
    该成分在$X_1$（固定资产）、$X_2$（职工人数）上载荷为正，而在$X_5$（百元固资产值）、$X_6$（资金利税率）上载荷显著为负。这反映了**企业规模与资金利用效率的权衡**。得分高的企业往往规模大（资产多、人数多），但单位资产的产出效率可能较低。

2.  **第二主成分 ($Y_2$)**：
    $$ Y_2 \approx 0.38X_1 + 0.49X_3 + 0.40X_4 $$
    该成分在$X_3$（工业总产值）、$X_4$（全员劳动生产率）以及$X_1$上均为较高的正载荷。这主要代表了企业的**综合产出能力与生产力水平**。

3.  **第三主成分 ($Y_3$)**：
    $$ Y_3 \approx -0.86X_8 + 0.37X_7 $$
    该成分主要由$X_8$（能源利用效果）负向主导。由于$X_8$载荷绝对值极大，该成分可被视为**能源消耗与利用指标**，反映了企业在能源层面的表现。

#### 3.3.2 样本回代预测
利用`predict`函数计算各样本在三个主成分上的得分（Scores），实现了从8维空间到3维空间的映射。例如，**企业2**在第一主成分上得分最高（4.49），说明其规模巨大；而**企业13**在第二主成分上得分极低（-3.07），暗示其综合生产力水平相对较弱。这些得分为后续的企业综合评价提供了量化依据。

### 3.4 综合可视化分析

#### 3.4.1 主成分载荷散点图
为了更清晰地展示变量间的关系，绘制了前两个主成分的载荷散点图。

<<<---图15-2（主成分载荷散点图，展示变量在PC1和PC2平面的分布）--->>>

从图15-2可以看出，变量被明显地分为了几簇。$X_1, X_2, X_3$在第一象限聚集，说明规模与产出高度相关；而效率指标$X_5, X_6$则位于左侧，与规模指标在第一主成分轴上形成对立，再次印证了“规模-效率”权衡的解释。

#### 3.4.2 双坐标图 (Biplot)
双坐标图同时展示了样本点（企业）和变量（经济指标）在主成分空间中的位置。

<<<---图15-3（Biplot双坐标图，同时展示样本分布与变量向量）--->>>

在图15-3中，向量的夹角反映变量相关性（夹角越小相关性越强），样本点的位置反映其特征。例如，若某企业样本点靠近$X_3$（工业总产值）向量的方向，说明该企业在产出方面表现突出。通过此图，我们可以快速识别出哪些企业在规模上占优，哪些企业在效率或能源利用上更具竞争力。

## 第四章 总结与心得

### 4.1 实验结果分析

本次课程设计通过两个独立的案例，分别展示了监督学习中的分类预测与无监督学习中的降维分析在实际数据处理中的应用效果。

在案例一的计算机购买行为预测中，我们对比了决策树（Decision Tree）与朴素贝叶斯（Naive Bayes）两种不同算法的表现。对于同一待预测样本$X$（30岁以下、收入中等、学生、信用良好），两种模型给出了截然相反的预测结论。`rpart`决策树模型将其分类为“否”（不购买），其预测路径主要受限于样本落在特定的叶节点规则中，更多地体现了基于已有规则的硬性切割；而`NaiveBayes`模型则将其分类为“是”（购买），且给出了高达65.4%的后验概率。这一差异深刻揭示了算法特性的不同：决策树倾向于寻找区分度最高的特征进行层级划分，容易忽略非分裂特征的综合影响；而朴素贝叶斯则基于概率论，综合考量了“学生”身份、“年龄”等所有特征的联合概率贡献。在小样本数据集下，贝叶斯模型往往能捕捉到变量间更细腻的概率联系。

在案例二的行业经济指标分析中，主成分分析（PCA）成功地解决了多重共线性问题。原始数据的相关系数矩阵显示变量间存在高度相关性，通过PCA方法，我们将8个原始经济指标成功降维为3个主成分，且这3个主成分解释了总体方差的88.1%，满足了信息保留的要求。通过对载荷矩阵的分析，我们将提取出的主成分赋予了明确的经济学意义：第一主成分反映了企业规模与资金效率的权衡，第二主成分代表了综合生产力水平，第三主成分则聚焦于能源利用。通过计算主成分得分和绘制双坐标图，我们不仅实现了数据的简化，还直观地揭示了不同企业在规模、效率和能源表现上的差异定位。

### 4.2 遇到的问题与体会

在本次实验的实施过程中，主要遇到了数据结构处理与模型解释两方面的挑战。

首先是R语言中数据类型的严格性问题。在进行分类预测时，最初构建的新样本`new_sample`未能正确指定因子水平（Levels），导致`predict`函数无法识别新数据与训练集的一致性。这一问题让我深刻体会到，在处理分类变量（Categorical Variables）时，保持训练集与测试集因子结构的一致是R语言建模的基石。此外，在主成分分析中，如何界定主成分个数也是一个难点，单纯依赖特征值大于1的标准与累积贡献率标准可能会得出不同结果，最终需结合碎石图与实际解释的可行性进行综合判断。

通过本次课程设计，我不仅掌握了`rpart`、`klaR`及`princomp`等核心函数的调用方法，更重要的是理解了“算法服务于数据”的理念。模型不仅仅是输出一个结果，更需要通过可视化（如决策树图、Biplot）来解释结果背后的逻辑。无论是分类中的概率权衡，还是降维中的信息重构，数学原理在R语言的高效实现下变得具体可感，提升了我利用统计工具解决复杂实际问题的能力。

---

## 附录：程序源代码

<<<---代码14.R（案例一：决策树与朴素贝叶斯分类预测完整代码）--->>>
<<<---代码15.R（案例二：企业经济指标主成分分析完整代码）--->>>